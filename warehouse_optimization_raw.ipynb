{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf508af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba68ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_list(lst1 , lst2):\n",
    "    cumulative_list = []\n",
    "    for i in range(len(lst1)):\n",
    "        cumulative_list.append(int(lst1[i] + lst2[i]))\n",
    "    \n",
    "    return cumulative_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4bb2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_turnover(df , T, topn, moving_avg = False):\n",
    "    \n",
    "    if moving_avg == True:\n",
    "        demand = df[df['type'] == 'OUT']\n",
    "        supply = df[df['type'] == 'IN']\n",
    "\n",
    "        # create a complete day_id for each product\n",
    "        merged_demand = demand.merge(complete_date, on = ['day_id', 'product_id'], how = 'outer')\n",
    "        merged_demand = merged_demand.sort_values(['product_id', 'day_id']).reset_index()\n",
    "        merged_demand = merged_demand[['day_id', 'product_id', 'quantity']]\n",
    "\n",
    "        # calculate the weekday for each data row\n",
    "        merged_demand['weekday'] = merged_demand['day_id'] % 6\n",
    "        merged_demand['week_id'] = (np.ceil(merged_demand['day_id'] / 6)).astype(int)\n",
    "        merged_demand = merged_demand.fillna(0)\n",
    "\n",
    "        # calculate the moving average. To concate the data, we rename the column name of moving average to quantity_new\n",
    "        merged_demand['quantity_new'] = merged_demand.groupby(['product_id', 'weekday'])['quantity'].transform((lambda x: x.rolling(17, 17).mean())).values\n",
    "        merged_demand['quantity_new'] = merged_demand.groupby(['product_id', 'weekday'])['quantity_new'].shift(1)\n",
    "        merged_demand = merged_demand.fillna(0)\n",
    "        merged_demand['type'] = 'OUT'\n",
    "        merged_demand = merged_demand[['day_id', 'week_id', 'product_id', 'quantity', 'type', 'quantity_new']]\n",
    "        # merged_demand.head(20)\n",
    "\n",
    "        # final dataset\n",
    "        merged_df = pd.concat([supply, merged_demand])\n",
    "        merged_df = merged_df.sort_values(['product_id', 'day_id']).reset_index()\n",
    "        merged_df = merged_df.drop('index', axis = 1)\n",
    "    \n",
    "        df = merged_df\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # add minus sign if the type is OUT\n",
    "    df['quantity_new'] = np.where(df['type'] == 'IN', df['quantity'], df['quantity'] * -1)\n",
    "\n",
    "    # calculate the net quantity\n",
    "    calculate_net_quantity = df.groupby(['product_id', 'day_id', 'type'])['quantity_new'].sum()\n",
    "    calculate_net_quantity = calculate_net_quantity.reset_index().sort_values(['day_id', 'product_id', 'type'])\n",
    "    calculate_net_quantity['grand total'] = abs(calculate_net_quantity['quantity_new'])\n",
    "    \n",
    "    # calculate the turnover rate\n",
    "    daily_turnover_rate = calculate_net_quantity[['day_id', 'product_id', 'grand total', 'quantity_new']]\n",
    "    daily_turnover_rate = daily_turnover_rate.groupby(['product_id', 'day_id'])[['quantity_new', 'grand total']].sum()\n",
    "    daily_turnover_rate['cummulative'] = daily_turnover_rate.groupby(['product_id'])['quantity_new'].cumsum()\n",
    "    daily_turnover_rate = daily_turnover_rate.reset_index()\n",
    "    \n",
    "    # avoid turnover rate from being negative values\n",
    "    daily_turnover_rate['turnover'] = daily_turnover_rate['grand total'] / (daily_turnover_rate['cummulative'] - daily_turnover_rate['cummulative'].min())\n",
    "    \n",
    "    # calculate the frequency based on T\n",
    "    daily_turnover_rate['frequency'] = (np.ceil(daily_turnover_rate['day_id'] / T)).astype(int)\n",
    "    \n",
    "    # sort by frequency\n",
    "    turnover_rate_series = daily_turnover_rate.groupby(['product_id', 'frequency'])['turnover'].sum() / T\n",
    "    turnover_rate_df = turnover_rate_series.reset_index()\n",
    "    result = daily_turnover_rate.merge(turnover_rate_df, on = ['product_id', 'frequency'])\n",
    "\n",
    "    # select necessary columns\n",
    "    result['IN'] = (result['grand total'] + result['quantity_new']) / 2\n",
    "    result['OUT'] = (result['grand total'] - result['quantity_new']) / 2\n",
    "    result = result[['product_id', 'frequency', 'day_id', 'IN', 'OUT', 'turnover_y']]\n",
    "    \n",
    "    # return topn product\n",
    "    product_list = result['product_id'].unique()\n",
    "    product_list = product_list[:topn]\n",
    "    result = result[result['product_id'].isin(product_list)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba46793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class product_object:\n",
    "    def __init__(self, product_id , number_of_classes):\n",
    "        self.number_of_classes = number_of_classes\n",
    "        self.product_id = product_id\n",
    "        self.current_inventory = [0] * (number_of_classes - 1) + [100000]###initiate starting inventory in all three classes\n",
    "        self.class_log = [] ### initiate a list for storing all the class logs\n",
    "\n",
    "    def update_storage_inbound(self , update_class_log):\n",
    "        self.current_inventory = add_list(self.current_inventory , update_class_log)\n",
    "        \n",
    "    def update_storage_outbound(self , number_of_product_to_take):\n",
    "        class_indexer = 0\n",
    "        \n",
    "        ### return a list of retrieval from each class\n",
    "        retrieve_table = [0] * self.number_of_classes\n",
    "        \n",
    "        ### create temp # product to record how many left to retrieve\n",
    "        number_of_product_to_retrieve = number_of_product_to_take\n",
    "        \n",
    "        while number_of_product_to_retrieve != 0:\n",
    "            subtract = number_of_product_to_retrieve - self.current_inventory[class_indexer]\n",
    "            \n",
    "            ### if class has enough product to retrieve from\n",
    "            if subtract <= 0:\n",
    "                self.current_inventory[class_indexer] = self.current_inventory[class_indexer] - number_of_product_to_retrieve\n",
    "                retrieve_table[class_indexer] = number_of_product_to_retrieve\n",
    "                number_of_product_to_retrieve = 0\n",
    "                break\n",
    "    \n",
    "            \n",
    "            ### if class doesn't have enough product to retrieve from\n",
    "            else:\n",
    "                number_of_product_to_retrieve = number_of_product_to_retrieve - self.current_inventory[class_indexer]\n",
    "                retrieve_table[class_indexer] = self.current_inventory[class_indexer]\n",
    "                self.current_inventory[class_indexer] = 0 ### all retrieved\n",
    "                class_indexer = class_indexer + 1\n",
    "        \n",
    "        return retrieve_table\n",
    "            \n",
    "            \n",
    "        self.current_inventory = add_list(self.current_inventory , update_class_log * -1)\n",
    "    \n",
    "    def tenor_update(self , tenor_id , update_class_log):\n",
    "        self.class_log.append([tenor_id , update_class_log])\n",
    "            \n",
    "    def print_all_class_logs(self):\n",
    "        class_column = [str(f\"Class {col_index}\") for col_index in range(1 , self.number_of_classes)]\n",
    "        class_column = class_column + 'Class backup'\n",
    "        df = pd.DataFrame([log[1] for log in self.class_log] , column = class_column)\n",
    "        df['tenor_index'] = [T[0] for T in self.class_log]\n",
    "    \n",
    "    def print_class_name(self):\n",
    "        print(self.product_id)\n",
    "        \n",
    "    def print_current_inventory(self):\n",
    "        print(self.current_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352cfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_object:\n",
    "    def __init__(self, class_id , n_products , max_capacity = 984 , if_backup = False):\n",
    "        self.class_id = class_id\n",
    "        self.max_capacity = max_capacity\n",
    "        self.current_inventory = np.zeros(n_products)\n",
    "        self.current_capacity = 0\n",
    "        \n",
    "        ### create unlimited backup class\n",
    "        if if_backup:\n",
    "            self.current_inventory = [100000] * n_products\n",
    "            self.max_capacity = 100000\n",
    "            self.current_capacity = sum(self.current_inventory)\n",
    "        \n",
    "\n",
    "\n",
    "    ### Inbound handling \n",
    "    def stuff_product(self, product_index , number_of_product): \n",
    "        spare_room = self.max_capacity - self.current_capacity ### check room left\n",
    "        product_index = int(product_index) ### convert index to int for indexing\n",
    "\n",
    "        if spare_room >= number_of_product: ### if enough room\n",
    "            self.current_inventory[product_index - 1] = self.current_inventory[product_index - 1] + number_of_product\n",
    "            self.current_capacity = sum(self.current_inventory) ### update capacity\n",
    "            return 0\n",
    "\n",
    "        else: ### if not enough room\n",
    "            self.current_inventory[product_index - 1] = self.current_inventory[product_index - 1] + spare_room ### stuff to max\n",
    "            self.current_capacity = self.max_capacity ### update capacity\n",
    "            return number_of_product - spare_room ### return number of products that are not stored\n",
    "    \n",
    "    ### Outbound handling\n",
    "    def take_product(self , product_index , retrieval_list):\n",
    "        self.current_inventory[product_index] = self.current_inventory[product_index] - retrieval_list[index]\n",
    "        self.current_capacity = sum(self.current_inventory)\n",
    "        \n",
    "    def return_numbers(self):\n",
    "        print('current inventory :' , self.current_inventory)\n",
    "        print('current capacity :' , self.current_capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1712ebc",
   "metadata": {},
   "source": [
    "### Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0c02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### warehouse data\n",
    "warehouse = pd.read_csv('data_source/warehouse_data.csv')\n",
    "### calculate turnover\n",
    "turnover_df = calculate_turnover(warehouse , 6 , 10) ### (datasource, T , top_n product)\n",
    "\n",
    "### travel distance\n",
    "travel_distance = pd.read_excel('data_source/travel distance.xlsx')\n",
    "storage_dist = list(travel_distance['Storage Distance'])\n",
    "retrieval_dist = list(travel_distance['Retrieval Distance'])\n",
    "\n",
    "### decide distance for backup storage\n",
    "backup_dist = [999]\n",
    "storage_dist = storage_dist + backup_dist\n",
    "retrieval_dist = retrieval_dist + backup_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d8792",
   "metadata": {},
   "source": [
    "### Initiate objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc09a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 4\n",
    "number_of_products = 10\n",
    "\n",
    "### initiate list of 4 classes\n",
    "class_object_list = []\n",
    "for i in range(1,5):\n",
    "    class_object_list.append(class_object(f\"{i}\" , number_of_products))\n",
    "\n",
    "### add one backup storage\n",
    "class_object_list.append(class_object(5 , number_of_products , if_backup = True))\n",
    "### adjust for backup class\n",
    "number_of_classes = number_of_classes + 1\n",
    "\n",
    "\n",
    "### initiate list of top ten products\n",
    "product_object_list = []\n",
    "for i in range(1,11):\n",
    "    product_object_list.append(product_object(f\"{i}\" , number_of_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91132892",
   "metadata": {},
   "source": [
    "### Product distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ded30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inbound_logs = []\n",
    "outbound_logs = []\n",
    "### for each tenor data\n",
    "for tenor in list(turnover_df.groupby('frequency')):\n",
    "    ### sort tenor data with day id and turnover\n",
    "    tenor_df = tenor[1].sort_values(['day_id' , 'turnover_y'] , ascending = [True, False])\n",
    "    ### tenor storing log\n",
    "    tenor_storing_log_outbound = [[0] * number_of_classes] * number_of_products\n",
    "    tenor_storing_log_inbound = [[0] * number_of_classes] * number_of_products\n",
    "    \n",
    "    ### for each log\n",
    "    for index , row in tenor_df.iterrows():\n",
    "        \n",
    "        ### handle inbound\n",
    "        storing_log = [0] * number_of_classes ### document all classes product i is stored\n",
    "        number_of_product_to_store = row['IN'] ### number of product to store\n",
    "        number_of_product_to_take = row['OUT'] ### number of product to take\n",
    "        temp_product_count = number_of_product_to_store\n",
    "        non_stored = number_of_product_to_store\n",
    "        product_id = int(row['product_id']) - 1\n",
    "        \n",
    "        for class_index in range(len(class_object_list)): ### enumerate through all the classes to store\n",
    "            ### try to store product into class\n",
    "            non_stored = class_object_list[class_index].stuff_product(row['product_id'] , non_stored)\n",
    "            class_i_stored = temp_product_count - non_stored\n",
    "            storing_log[class_index] =  class_i_stored  ### record log\n",
    "\n",
    "            ### if completely stored\n",
    "            if non_stored == 0:\n",
    "                ### calculate row change log\n",
    "                temp_log = add_list(tenor_storing_log_inbound[product_id] , storing_log)\n",
    "                ### update product log\n",
    "                tenor_storing_log_inbound[product_id] = temp_log\n",
    "                ### update product object\n",
    "                product_object_list[product_id].update_storage_inbound(storing_log)\n",
    "                break\n",
    "\n",
    "            ### if not enough storage\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        ### handle outbound\n",
    "        if number_of_product_to_take == 0: ### if no outbound, go to next row\n",
    "            continue\n",
    "        else:\n",
    "            ### table of what to retrieve from which table\n",
    "            retrieve_table = product_object_list[product_id].update_storage_outbound(number_of_product_to_take)\n",
    "            for index in range(len(retrieve_table)):\n",
    "                class_object_list[index].take_product(product_id , retrieve_table)\n",
    "            \n",
    "            ### update tenor_list\n",
    "            tenor_storing_log_outbound[product_id] = add_list(tenor_storing_log_outbound[product_id] , retrieve_table)\n",
    "            \n",
    "    ### store all the logs\n",
    "    inbound_logs.append(tenor_storing_log_inbound)\n",
    "    outbound_logs.append(tenor_storing_log_outbound)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe2570",
   "metadata": {},
   "source": [
    "### calculate_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a983201",
   "metadata": {},
   "outputs": [],
   "source": [
    "### inbound\n",
    "inbound_distance = 0\n",
    "for tenor_log in inbound_logs:\n",
    "    for product_log in tenor_log:\n",
    "        for class_index in range(len(product_log)):\n",
    "            inbound_distance = inbound_distance + product_log[class_index] * storage_dist[class_index]\n",
    "\n",
    "### outbound\n",
    "outbound_distance = 0\n",
    "for tenor_log in outbound_logs:\n",
    "    for product_log in tenor_log:\n",
    "        for class_index in range(len(product_log)):\n",
    "            outbound_distance = outbound_distance + product_log[class_index] * retrieval_dist[class_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafb2fe",
   "metadata": {},
   "source": [
    "### inbound distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7da6be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10105978.600000003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbound_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299fa739",
   "metadata": {},
   "source": [
    "### outbound distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad3aeb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14186550.900000006"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outbound_distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
